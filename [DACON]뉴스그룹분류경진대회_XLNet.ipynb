{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[DACON]뉴스그룹분류경진대회-XLNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "by70T_Bc2296",
        "NqJqvEO9gn2k",
        "L2iigeTj3OBq",
        "TnezbPYyevg8",
        "ED0u7PcllO9d",
        "gpxrCZTyfRTf",
        "mbhOyq-qg9nh"
      ],
      "authorship_tag": "ABX9TyMf9NNFuvbPO31NRi9TMp2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzhenxi/Competitions/blob/main/%5BDACON%5D%EB%89%B4%EC%8A%A4%EA%B7%B8%EB%A3%B9%EB%B6%84%EB%A5%98%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C_XLNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [NOTE]\n",
        "- dacon pretrained 모델 사용 금지 규칙이 있으므로 해당 코드는 제출에 사용되지 않았습니다."
      ],
      "metadata": {
        "id": "GqwYwUkKeMNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 불러오기"
      ],
      "metadata": {
        "id": "by70T_Bc2296"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bJ8sV019fpqS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD9PbG4CfyZC",
        "outputId": "0a21a4de-c111-4711-e3dd-0cb66a02b78f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/drive/MyDrive/dacon"
      ],
      "metadata": {
        "id": "DDRpthqigQFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -qq \"/content/drive/MyDrive/dacon/뉴스그룹분류경진대회.zip\""
      ],
      "metadata": {
        "id": "FtBdzSHOf5Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/dacon/train.csv')"
      ],
      "metadata": {
        "id": "NqJua-ihgRJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "mDinOSlBgg36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리\n",
        "- 중복 / 결측치 확인\n",
        "- \\n 제거\n",
        "- 특수문자 제거 (내용에 영향을 주는 경우도 있어 보류)\n",
        "- 소문자 통합"
      ],
      "metadata": {
        "id": "NqJqvEO9gn2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복 / 결측치 확인 \n",
        "train_df.duplicated().sum(), train_df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9Qsx5AQjkzf",
        "outputId": "ee1336e2-3fdb-4445-ff3c-c6397ebf2a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특수문자 제거\n",
        "import re\n",
        "\n",
        "def clean_text(inputString):\n",
        "  text_rmv = re.sub('[-=+,#/\\?:^.@*\\\"※~ㆍ!』‘|\\(\\)\\[\\]`\\'…》\\”\\“\\’·]', '', inputString)\n",
        "  return text_rmv"
      ],
      "metadata": {
        "id": "bhslEDK1kjl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.text = train_df.text.apply(clean_text)"
      ],
      "metadata": {
        "id": "YPOraA1qlbaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \\n 제거\n",
        "train_df.replace('\\n', '', regex=True, inplace=True)"
      ],
      "metadata": {
        "id": "kKd7l_bDlm-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 소문자 통합\n",
        "train_df.text = train_df.text.str.lower()"
      ],
      "metadata": {
        "id": "pIOjLTpwmxWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 된 data 저장\n",
        "# train_df.to_csv('/content/drive/MyDrive/dacon/preprocessed_train.csv')"
      ],
      "metadata": {
        "id": "nCzf8ktInJtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리2\n",
        "* 전처리된 데이터가 구글 드라이브에 저장되어 있는 경우, 이 쉘을 실행"
      ],
      "metadata": {
        "id": "L2iigeTj3OBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/dacon/preprocessed_train.csv', lineterminator='\\n')"
      ],
      "metadata": {
        "id": "hvEixTde2uM3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ts3GnudN3nVN",
        "outputId": "82d61fa1-95dc-48a7-e0fc-2e67641f1ff3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  id                                               text  target\n",
              "0           0   0  they were and even if washington might conside...      10\n",
              "1           1   1  we run spacenews & views on our stareach bbs a...      14\n",
              "2           2   2  not to worry  the masons have been demonized a...      19\n",
              "3           3   3  only brendan mckay or maybe arf would come to ...      17\n",
              "4           4   4  help i am running some sample problems from or...       5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b620f44-80b6-4ff9-b99f-4dbf3394397b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>they were and even if washington might conside...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>we run spacenews &amp; views on our stareach bbs a...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>not to worry  the masons have been demonized a...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>help i am running some sample problems from or...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b620f44-80b6-4ff9-b99f-4dbf3394397b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b620f44-80b6-4ff9-b99f-4dbf3394397b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b620f44-80b6-4ff9-b99f-4dbf3394397b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "X0H0mcvO3a8A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RnIGllh74D37",
        "outputId": "f2fbec29-5144-4694-bba7-78826bd8c6c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                               text  target\n",
              "0   0  they were and even if washington might conside...      10\n",
              "1   1  we run spacenews & views on our stareach bbs a...      14\n",
              "2   2  not to worry  the masons have been demonized a...      19\n",
              "3   3  only brendan mckay or maybe arf would come to ...      17\n",
              "4   4  help i am running some sample problems from or...       5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce63008e-ac1b-4fa5-bde0-e8e7f4d3414d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>they were and even if washington might conside...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>we run spacenews &amp; views on our stareach bbs a...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>not to worry  the masons have been demonized a...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>help i am running some sample problems from or...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce63008e-ac1b-4fa5-bde0-e8e7f4d3414d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce63008e-ac1b-4fa5-bde0-e8e7f4d3414d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce63008e-ac1b-4fa5-bde0-e8e7f4d3414d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[에러해결] tokenizer encoding을 하는 과정에서 nan값이 포함되었다고 하여, 결측치 제거"
      ],
      "metadata": {
        "id": "1cUk7rmYqJtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "ApyFA59AqFjV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델링"
      ],
      "metadata": {
        "id": "2vqJszrQerEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set gpu enviroment"
      ],
      "metadata": {
        "id": "TnezbPYyevg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "6KEFv--CfFxy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "metadata": {
        "id": "ZjmxX7IHeupv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxIItD75fMLc",
        "outputId": "2f4f900c-0e56-481d-c6ed-87a0e18f046b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### parser data"
      ],
      "metadata": {
        "id": "BVHazTH4oMHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sentence data\n",
        "sentences = train_df.text.to_list()\n",
        "sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JKTfmCTUoLRD",
        "outputId": "759d252d-f323-41ac-d3ce-bf092341b896"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'they were and even if washington might consider patty a bust id reworkthat trade in a minute  druce has been a complete and utter bust hereonly 5 goals'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get tag labels data\n",
        "labels = train_df.target.to_list()\n",
        "print(labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1nzNrA_oQAo",
        "outputId": "592eae92-4daf-46f8-af14-f3cbe2036913"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a dict for mapping id to tag name\n",
        "#tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
        "\n",
        "# Recommend to set it by manual define, good for reusing\n",
        "# 0:negative, 1: positive\n",
        "tag2idx={'0': 0,\n",
        " '1': 1}"
      ],
      "metadata": {
        "id": "xbAH-eaTpbDT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df.target.unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8v5L2FMsTai",
        "outputId": "83644359-6b4b-46e9-ab88-e8fe227b5d13"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 카테고리가 총 20개이므로 \n",
        "tag2idx={}\n",
        "for i in range(20):\n",
        "  tag2idx[f'{i}'] = i"
      ],
      "metadata": {
        "id": "u7KJSrxMulkN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}"
      ],
      "metadata": {
        "id": "fbmIrLjVw76C"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sentencepiece model download\n",
        "* 이미 다운로드 되었다면 실행할 필요 없음"
      ],
      "metadata": {
        "id": "ED0u7PcllO9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/dacon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSiLwDo_iifK",
        "outputId": "f50eecc6-5d46-4236-9e17-4b5efa135e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dacon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LbvMiOOtikC8",
        "outputId": "58bf8e3e-915c-454d-ef3c-3e266aab42bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/dacon'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jc2jHXbinrA",
        "outputId": "ade68646-8018-4ba9-962b-752445eea6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-08 05:10:23--  https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.15.38\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.15.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 798011 (779K) [binary/octet-stream]\n",
            "Saving to: ‘xlnet-base-cased-spiece.model’\n",
            "\n",
            "xlnet-base-cased-sp 100%[===================>] 779.31K  2.43MB/s    in 0.3s    \n",
            "\n",
            "2022-04-08 05:10:24 (2.43 MB/s) - ‘xlnet-base-cased-spiece.model’ saved [798011/798011]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls # 모델이 잘 다운로드 되었는지 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmmAfGk0lLEF",
        "outputId": "ef71e914-db16-45d2-ed0f-a563bfd14ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessed_train.csv  test.csv   xlnet-base-cased-spiece.model\n",
            "sample_submission.csv   train.csv  뉴스그룹분류경진대회.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load tokenizer\n",
        "* vocab_file에 sentencepiece 사용 "
      ],
      "metadata": {
        "id": "gpxrCZTyfRTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "id": "YF4FovT9fYF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ffb977-9360-4044-c6bb-beeb4a800078"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 17.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 8.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "DSFKBRNrf0n2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495bb1ba-c455-4cb4-c957-1dd78e867892"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 8.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 67.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/dacon"
      ],
      "metadata": {
        "id": "Es95JBczl1K6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b68333-6460-4d2e-8d1e-e134ffd1ba94"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dacon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = 'xlnet-base-cased-spiece.model' # 상대경로임"
      ],
      "metadata": {
        "id": "j25OK-gcfdpC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len  = 64"
      ],
      "metadata": {
        "id": "QuMsoRJ9fpNh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer)"
      ],
      "metadata": {
        "id": "aB1VrXIWfy5U"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = XLNetTokenizer(vocab_file=vocabulary, do_lower_case=False)"
      ],
      "metadata": {
        "id": "dVXPWgS3frpC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### set text input embedding\n"
      ],
      "metadata": {
        "id": "Dpdg3yhcnetU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 코드에 대한 내용은 xlnet githug repo\n",
        "* https://github.com/zihangdai/xlnet/blob/master/data_utils.py\n",
        "* https://github.com/zihangdai/xlnet/blob/master/classifier_utils.py  \n",
        " \n",
        "에 정의되어 있다.   \n",
        "\n",
        "생성되는 임배딩\n",
        "- token id embedding\n",
        "- mask embedding\n",
        "- segment embedding\n",
        "\n",
        "- Token type id 란? (segment id 라고도 부름)\n",
        "BERT와 같은 모델에서는 입력으로 2개의 문장이 주어지는 경우가 있다. 입력으로 문장이 2개가 주어진 경우, 두 문장을 구분할 수 있도록 별도의 id를 부여한다. 2개의 문장이 입력으로 주어지면, 첫 번째 문장에 해당하는 token들의 인덱스에는 모두 0을, 두 번째 문장에 해당하는 token들의 인덱스에는 모두 1을 부여한다. "
      ],
      "metadata": {
        "id": "LVClc7n6mQk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len  = 64\n",
        "\n",
        "full_input_ids = []\n",
        "full_input_masks = []\n",
        "full_segment_ids = []"
      ],
      "metadata": {
        "id": "SCpcMK1ayhsm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEG_ID_A   = 0\n",
        "SEG_ID_B   = 1\n",
        "SEG_ID_CLS = 2\n",
        "SEG_ID_SEP = 3\n",
        "SEG_ID_PAD = 4"
      ],
      "metadata": {
        "id": "m6AThQ2Wyiy6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_ID = tokenizer.encode(\"<unk>\")[0]\n",
        "CLS_ID = tokenizer.encode(\"<cls>\")[0]\n",
        "SEP_ID = tokenizer.encode(\"<sep>\")[0]\n",
        "MASK_ID = tokenizer.encode(\"<mask>\")[0]\n",
        "EOD_ID = tokenizer.encode(\"<eod>\")[0]"
      ],
      "metadata": {
        "id": "SXiSQ3v1ykbH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentences):\n",
        "    # Tokenize sentence to token id list\n",
        "    tokens_a = tokenizer.encode(sentence)\n",
        "    \n",
        "    # Trim the len of text -> token 갯수 조정\n",
        "    if(len(tokens_a)>max_len-2):\n",
        "        tokens_a = tokens_a[:max_len-2]\n",
        "        # 2를 빼는 이유는 special token 때문인듯\n",
        "        \n",
        "    tokens = []\n",
        "    segment_ids = [] # 필요한 이유?\n",
        "    \n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(SEG_ID_A) # 위치...?\n",
        "        \n",
        "    # Add <sep> token \n",
        "    tokens.append(SEP_ID) \n",
        "    segment_ids.append(SEG_ID_A)\n",
        "    \n",
        "    \n",
        "    # Add <cls> token\n",
        "    tokens.append(CLS_ID)\n",
        "    segment_ids.append(SEG_ID_CLS) # 한 문장의 끝\n",
        "    \n",
        "    input_ids = tokens\n",
        "    \n",
        "    # The mask has 0 for real tokens and 1 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [0] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length at fornt \n",
        "    # max_len 만큼 '문장의 앞에' 제로패딩 \n",
        "    if len(input_ids) < max_len:\n",
        "        delta_len = max_len - len(input_ids)\n",
        "        input_ids = [0] * delta_len + input_ids\n",
        "        input_mask = [1] * delta_len + input_mask\n",
        "        segment_ids = [SEG_ID_PAD] * delta_len + segment_ids\n",
        "\n",
        "    assert len(input_ids) == max_len\n",
        "    assert len(input_mask) == max_len\n",
        "    assert len(segment_ids) == max_len\n",
        "    \n",
        "    full_input_ids.append(input_ids)\n",
        "    full_input_masks.append(input_mask)\n",
        "    full_segment_ids.append(segment_ids)\n",
        "    \n",
        "    if i==0: # 한개만 출력\n",
        "        print(\"No.:%d\"%(i))\n",
        "        print(\"sentence: %s\"%(sentence))\n",
        "        print(\"input_ids:%s\"%(input_ids))\n",
        "        print(\"attention_masks:%s\"%(input_mask))\n",
        "        print(\"segment_ids:%s\"%(segment_ids))\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BjSlRghynIx",
        "outputId": "a429240b-0fa5-49dd-e350-fecdb08f0fb8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.:0\n",
            "sentence: they were and even if washington might consider patty a bust id reworkthat trade in a minute  druce has been a complete and utter bust hereonly 5 goals\n",
            "input_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 63, 55, 21, 176, 108, 11048, 577, 327, 1524, 15300, 982, 24, 11417, 17, 1500, 17, 88, 3552, 4331, 750, 25, 24, 1901, 17, 7841, 11735, 51, 72, 24, 1009, 21, 17, 9035, 11417, 193, 6632, 306, 1667, 4, 3, 7739, 7739]\n",
            "attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "segment_ids:[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"<cls>\"), tokenizer.encode(\"<unk>\") # 왜 스페셜 토큰은 같은 임베딩 값일까? -> 나중에 업데이트 되어서 이지 않을까?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ergh8QvyrhDm",
        "outputId": "f5b6e157-00e4-46a3-a810-80708331a4e4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([7739, 11974, 23, 3151, 4, 3], [7739, 12287, 3151, 4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## set label embedding "
      ],
      "metadata": {
        "id": "6dYQLL3mr7fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make label into id\n",
        "# label값을 id로 바꿔주기 : 그런데 무슨 차이가 있는지는 모르겠다..\n",
        "tags = [tag2idx[str(lab)] for lab in labels]\n",
        "print(tags[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v3wG8g_sEZ3",
        "outputId": "4ac69bcb-f9e8-4f76-f4c9-bcf43853bbfe"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train test split"
      ],
      "metadata": {
        "id": "5_e1S-v8x8K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "qnhlRbDlyBp9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "full_input_ids, full_input_masks, full_segment_ids는 모두 이중 리스트의 형태를 띈다.\n",
        "[[토큰들], [토큰들], [토큰들]]\n",
        "'''\n",
        "tr_inputs, val_inputs, tr_tags, val_tags,tr_masks, val_masks, tr_segs, val_segs = train_test_split(full_input_ids, tags, full_input_masks, full_segment_ids, \n",
        "                                                            random_state=1004, test_size=0.3)"
      ],
      "metadata": {
        "id": "rR39fnrnyIv4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tr_inputs),len(val_inputs),len(tr_segs),len(val_segs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNAh2ltu5gS_",
        "outputId": "33886f76-a436-4722-b454-5ec8b4fad163"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6412, 2748, 6412, 2748)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서로 변환\n",
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "tr_segs = torch.tensor(tr_segs)\n",
        "val_segs = torch.tensor(val_segs)"
      ],
      "metadata": {
        "id": "Lt3Uwdil59PB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader에 넣어주기"
      ],
      "metadata": {
        "id": "Xo3eycJb6rHF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set batch num\n",
        "batch_num = 32"
      ],
      "metadata": {
        "id": "pS78wdUj6woL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "M1eS9FYd7YUs"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set token embedding, attention embedding, segment embedding\n",
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_segs, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# Drop last can make batch training better for the last one\n",
        "# if drop_last is true, the sampler will drop the last batch if its size would be less than batch_size\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_num, drop_last=True)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks,val_segs, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
      ],
      "metadata": {
        "id": "rk5GpmJL6044"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train model"
      ],
      "metadata": {
        "id": "v_OgfEc5AyoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "from transformers import XLNetForSequenceClassification\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=len(tag2idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRAj7-4TBOnc",
        "outputId": "15bea934-d55e-4eaa-f745-e0f488d7f8fd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvapz5BIB0Lh",
        "outputId": "fd405fb0-a16d-4371-c45a-78f1c845cbc1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set epoch and grad max num\n",
        "epochs = 5\n",
        "max_grad_norm = 1.0"
      ],
      "metadata": {
        "id": "G2s8yAl-CQG2"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cacluate train optimiazaion num\n",
        "import math\n",
        "num_train_optimization_steps = int( math.ceil(len(tr_inputs) / batch_num) / 1) * epochs"
      ],
      "metadata": {
        "id": "w7_Cy_LZCUuc"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set fine tuning method"
      ],
      "metadata": {
        "id": "B33wDZkOLK7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# True: fine tuning all the layers \n",
        "# False: only fine tuning the classifier layers\n",
        "# Since XLNet in 'pytorch_transformer' did not contian classifier layers\n",
        "# FULL_FINETUNING = True need to set True\n",
        "FULL_FINETUNING = True"
      ],
      "metadata": {
        "id": "_A3hctLlLHpj"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam"
      ],
      "metadata": {
        "id": "1TLDgi-WLV8r"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 조금더 공부하기 \n",
        "\n",
        "if FULL_FINETUNING:\n",
        "    # Fine tune model all layer parameters\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    # Only fine tune classifier parameters\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "metadata": {
        "id": "b8urxWGVLNWT"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fine-tuning model"
      ],
      "metadata": {
        "id": "dnO6EJuzLlWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model train 모드로 전환\n",
        "model.train() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4blDGeCLot4",
        "outputId": "fa40be86-81ab-4b11-a6d5-b89aebe4415e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm,trange"
      ],
      "metadata": {
        "id": "H30v2iK8TXGg"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"***** Running training *****\")\n",
        "print(\"  Num examples = %d\"%(len(tr_inputs)))\n",
        "print(\"  Batch size = %d\"%(batch_num))\n",
        "print(\"  Num steps = %d\"%(num_train_optimization_steps))\n",
        "for _ in trange(epochs,desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_segs,b_labels = batch\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(input_ids =b_input_ids,token_type_ids=b_segs, input_mask = b_input_mask,labels=b_labels)\n",
        "        loss, logits = outputs[:2]\n",
        "        if n_gpu>1:\n",
        "            # When multi gpu, average it\n",
        "            loss = loss.mean()\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        \n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3lpIBAZTCH8",
        "outputId": "6473745b-9eb9-4b58-9312-ec8e78c11945"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 6412\n",
            "  Batch size = 32\n",
            "  Num steps = 1005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  20%|██        | 1/5 [01:25<05:43, 85.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.852290170788765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 2/5 [02:55<04:24, 88.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.1271612000465394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 3/5 [04:27<03:00, 90.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.8256372323632241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 4/5 [06:01<01:31, 91.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.5893865446001292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 5/5 [07:35<00:00, 91.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.4058284097164869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save model"
      ],
      "metadata": {
        "id": "7YtCBo5nbNHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xlnet_out_address = 'models/xlnet_out_model/tc02'"
      ],
      "metadata": {
        "id": "F05ifvcfbPHl"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make dir if not exits\n",
        "if not os.path.exists(xlnet_out_address):\n",
        "        os.makedirs(xlnet_out_address)"
      ],
      "metadata": {
        "id": "hUVIVXc4bRqx"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a trained model, configuration and tokenizer\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self"
      ],
      "metadata": {
        "id": "uS_iXox9bU-u"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "output_model_file = os.path.join(xlnet_out_address, \"pytorch_model.bin\")\n",
        "output_config_file = os.path.join(xlnet_out_address, \"config.json\")"
      ],
      "metadata": {
        "id": "R30cwbJvbXkU"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model into file\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(xlnet_out_address)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OWrn0sqbbrC",
        "outputId": "8153fdb6-b646-42b6-ebd6-bab34b1ecf85"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('models/xlnet_out_model/tc02/spiece.model',)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load saved model"
      ],
      "metadata": {
        "id": "C9FyBHRacZOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = XLNetForSequenceClassification.from_pretrained(xlnet_out_address,num_labels=len(tag2idx))"
      ],
      "metadata": {
        "id": "NjgjSpiFcatm"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U47_U7Bvcerf",
        "outputId": "426b09c3-f4a4-4b53-907d-4feecc791576"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "eval model"
      ],
      "metadata": {
        "id": "u56OjDCKci6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "HMGI704fcu68"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eval mode로 전환\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "5D5bgqWVckJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set acc funtion\n",
        "def accuracy(out, labels):\n",
        "    outputs = np.argmax(out, axis=1)\n",
        "    return np.sum(outputs == labels)"
      ],
      "metadata": {
        "id": "kjKNRhl9cnHe"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "y_true = []\n",
        "y_predict = []\n",
        "print(\"***** Running evaluation *****\")\n",
        "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
        "print(\"  Batch size = {}\".format(batch_num))\n",
        "for step, batch in enumerate(valid_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_segs,b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids =b_input_ids,token_type_ids=b_segs, input_mask = b_input_mask,labels=b_labels)\n",
        "        tmp_eval_loss, logits = outputs[:2]\n",
        "    \n",
        "    # Get textclassification predict result\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    tmp_eval_accuracy = accuracy(logits, label_ids)\n",
        "#     print(tmp_eval_accuracy)\n",
        "#     print(np.argmax(logits, axis=1))\n",
        "#     print(label_ids)\n",
        "    \n",
        "    # Save predict and real label reuslt for analyze\n",
        "    for predict in np.argmax(logits, axis=1):\n",
        "        y_predict.append(predict)\n",
        "        \n",
        "    for real_result in label_ids.tolist():\n",
        "        y_true.append(real_result)\n",
        "\n",
        "    \n",
        "    eval_loss += tmp_eval_loss.mean().item()\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "   \n",
        "    nb_eval_steps += 1\n",
        "    \n",
        "    \n",
        "eval_loss = eval_loss / nb_eval_steps\n",
        "eval_accuracy = eval_accuracy / len(val_inputs)\n",
        "loss = tr_loss/nb_tr_steps \n",
        "result = {'eval_loss': eval_loss,\n",
        "                  'eval_accuracy': eval_accuracy,\n",
        "                  'loss': loss}\n",
        "report = classification_report(y_pred=np.array(y_predict),y_true=np.array(y_true))\n",
        "\n",
        "# Save the report into file\n",
        "output_eval_file = os.path.join(xlnet_out_address, \"eval_results.txt\")\n",
        "with open(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "        print(\"  %s = %s\"%(key, str(result[key])))\n",
        "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "        \n",
        "    print(report)\n",
        "    writer.write(\"\\n\\n\")  \n",
        "    writer.write(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG1Gf-b9cria",
        "outputId": "26f7ba76-fa67-4723-e951-48342faef575"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Running evaluation *****\n",
            "  Num examples =2748\n",
            "  Batch size = 32\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.6859534206695779\n",
            "  eval_loss = 1.1993423416170963\n",
            "  loss = 0.4058284097164869\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.47      0.43       116\n",
            "           1       0.63      0.61      0.62       138\n",
            "           2       0.62      0.69      0.65       151\n",
            "           3       0.51      0.67      0.58       131\n",
            "           4       0.75      0.64      0.69       140\n",
            "           5       0.79      0.79      0.79       125\n",
            "           6       0.83      0.78      0.80       158\n",
            "           7       0.80      0.74      0.77       155\n",
            "           8       0.73      0.66      0.70       125\n",
            "           9       0.75      0.82      0.79       146\n",
            "          10       0.80      0.80      0.80       143\n",
            "          11       0.70      0.76      0.73       163\n",
            "          12       0.70      0.58      0.63       133\n",
            "          13       0.84      0.85      0.84       150\n",
            "          14       0.78      0.71      0.74       136\n",
            "          15       0.67      0.78      0.72       149\n",
            "          16       0.55      0.72      0.62       143\n",
            "          17       0.84      0.68      0.75       147\n",
            "          18       0.58      0.40      0.47       117\n",
            "          19       0.37      0.27      0.31        82\n",
            "\n",
            "    accuracy                           0.69      2748\n",
            "   macro avg       0.68      0.67      0.67      2748\n",
            "weighted avg       0.69      0.69      0.69      2748\n",
            "\n"
          ]
        }
      ]
    }
  ]
}